{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NameToCategory\n",
    "Here, I create a function that's used for creating a \"Title\" feature by pulling out `Mr` `Miss`, etc. \n",
    "\n",
    "For groups that only a few ended up being bucketed into, I made a catch-all `Other` group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull out name into something more useful. \n",
    "import re\n",
    "mrPattern = re.compile('.*Mr\\..*')\n",
    "missPattern = re.compile('.*Miss\\..*')\n",
    "masterPattern = re.compile('.*Master\\..*')\n",
    "mrsPattern = re.compile('.*Mrs\\..*')\n",
    "donPattern = re.compile('.*Don\\..*')\n",
    "revPattern = re.compile('.*Rev\\..*')\n",
    "drPattern = re.compile('.*Dr\\..*')\n",
    "mmePattern = re.compile('.*Mme\\..*')\n",
    "msPattern = re.compile('.*Ms\\..*')\n",
    "majorPattern = re.compile('.*Major\\..*')\n",
    "ladyPattern = re.compile('.*Lady\\..*')\n",
    "sirPattern = re.compile('.*Sir\\..*')\n",
    "mllePattern = re.compile('.*Mlle\\..*')\n",
    "colPattern = re.compile('.*Col\\..*')\n",
    "captPattern = re.compile('.*Capt\\..*')\n",
    "countessPattern = re.compile('.*Countess\\..*')\n",
    "jonkheerPattern = re.compile('.*Jonkheer\\..*')\n",
    "\n",
    "def nameToCategory(name):\n",
    "    if (mrPattern.match(name)):\n",
    "        return 'Mr'\n",
    "    elif (jonkheerPattern.match(name)):\n",
    "        return 'Other'\n",
    "    elif (countessPattern.match(name)):\n",
    "        return 'Other'\n",
    "    elif (captPattern.match(name)):\n",
    "        return 'Other'\n",
    "    elif (missPattern.match(name)):\n",
    "        return 'Miss'\n",
    "    elif (masterPattern.match(name)):\n",
    "        return 'Master'\n",
    "    elif (mrsPattern.match(name)):\n",
    "        return 'Mrs'\n",
    "    elif (donPattern.match(name)):\n",
    "        return 'Other'\n",
    "    elif (revPattern.match(name)):\n",
    "        return 'Other'\n",
    "    elif (drPattern.match(name)):\n",
    "        return 'Other'\n",
    "    elif (mmePattern.match(name)):\n",
    "        return 'Mrs'\n",
    "    elif (msPattern.match(name)):\n",
    "        return 'Miss'\n",
    "    elif (majorPattern.match(name)):\n",
    "        return 'Other'\n",
    "    elif (ladyPattern.match(name)):\n",
    "        return 'Other'\n",
    "    elif (sirPattern.match(name)):\n",
    "        return 'Other'\n",
    "    elif (mllePattern.match(name)):\n",
    "        return 'Miss'\n",
    "    elif (colPattern.match(name)):\n",
    "        return 'Other'\n",
    "    return 'Other'\n",
    "#    raise Exception(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub\n",
    "This function reads in a csv, and cleans up the data to fill in missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def scrub(filePath):\n",
    "    data = pd.read_csv(filePath)\n",
    "    char_cabin = data['Cabin'].astype(str)\n",
    "    new_cabin = np.array([cabin[0] for cabin in char_cabin])\n",
    "    data['Cabin'] = pd.Categorical(new_cabin)\n",
    "\n",
    "    data['Fare'] = data['Fare'].fillna(data['Fare'].mean())\n",
    "    \n",
    "    c1Median = data.Age[data.Pclass == 1].median()\n",
    "    c2Median = data.Age[data.Pclass == 2].median()\n",
    "    c3Median = data.Age[data.Pclass == 3].median()\n",
    "\n",
    "    def medianFor(row):\n",
    "        if (row['Pclass'] == 1):\n",
    "            return c1Median\n",
    "        elif (row['Pclass'] == 2):\n",
    "            return c2Median\n",
    "        elif (row['Pclass'] == 3):\n",
    "            return c3Median\n",
    "        else:\n",
    "            raise Exception('Goofed')\n",
    "    \n",
    "    def updateAge(row):\n",
    "        if (math.isnan(row['Age'])):\n",
    "            median = medianFor(row)\n",
    "            row['Age'] = median\n",
    "        return row\n",
    "    \n",
    "    # Update the missing ages with the median\n",
    "    data = data.apply(updateAge, axis=1)\n",
    "    \n",
    "    new_embarked = np.where(data['Embarked'].isnull()\n",
    "                           , 'S'\n",
    "                           , data['Embarked'])\n",
    "    \n",
    "    data['Embarked'] = new_embarked\n",
    "    \n",
    "    data['Title'] = data['Name'].apply(nameToCategory)\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_scrub(df):\n",
    "    fixed = df.drop(['Name', 'Ticket', 'Fare', 'PassengerId'], axis=1)\n",
    "    fixedWithDummies = pd.get_dummies(fixed)\n",
    "    return fixedWithDummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scrubbedData = scrub('train.csv')\n",
    "scrubbedData = svm_scrub(scrubbedData)\n",
    "scrubbedData_X = scrubbedData.drop('Survived', axis=1)\n",
    "scrubbedData_y = scrubbedData.Survived\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ballparksC = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]\n",
    "ballparksGamma = [1e-5, 3e-5, 1e-4, 3e-4, 1e-3]\n",
    "\n",
    "splits = []\n",
    "for i in range(100):\n",
    "    test, train = train_test_split( scrubbedData\n",
    "                                   , test_size=0.2)\n",
    "    train_X = train.drop('Survived', axis=1)\n",
    "    train_y = train.Survived\n",
    "    test_X = test.drop('Survived', axis=1)\n",
    "    test_y = test.Survived\n",
    "    splits.append([train_X, train_y, test_X, test_y])\n",
    "bestScore = 0\n",
    "for gamma in ballparksGamma:\n",
    "    for C in ballparksC:\n",
    "        scoreTotal = 0\n",
    "        for split in splits:\n",
    "            classifier = SVC( C=C, gamma=gamma)\n",
    "            classifier.fit(split[0], split[1])\n",
    "            scoreTotal = scoreTotal + classifier.score(X=split[2], y=split[3])\n",
    "        average = scoreTotal / len(splits)\n",
    "        if (average > bestScore):\n",
    "            print(str(average) + ' C: ' + str(C) + ', gamma: ' + str(gamma))\n",
    "            bestScore=average\n",
    "            bestC = C\n",
    "            bestGamma = gamma\n",
    "\n",
    "classifier = SVC(C=bestC, gamma=bestGamma)\n",
    "classifier.fit(scrubbedData_X, scrubbedData_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train, test = train_test_split( scrubbedData\n",
    "                               , test_size=0.2\n",
    "                               , random_state = 1)\n",
    "\n",
    "## sans y\n",
    "train_X = train.drop('Survived', axis=1)\n",
    "train_y = train.Survived\n",
    "\n",
    "test_X = test.drop('Survived', axis=1)\n",
    "test_y = test.Survived\n",
    "\n",
    "svm_train_score = classifier.score(X=train_X, y=train_y)\n",
    "svm_test_score = classifier.score(X=test_X, y=test_y)\n",
    "\n",
    "print([svm_train_score, svm_test_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_for_submit = scrub('test.csv')\n",
    "test_for_submit = svm_scrub(test_for_submit)\n",
    "\n",
    "## Adding a label that doesn't exist in any of the test data. TODO: ask Jeremy if there is a way to do this better?\n",
    "test_for_submit.insert(14, 'Cabin_T', 0)\n",
    "\n",
    "submit_preds = classifier.predict(X=test_for_submit)\n",
    "\n",
    "submission = pd.DataFrame({ \"PassengerId\": scrub('test.csv')[\"PassengerId\"]\n",
    "                          , \"Survived\":submit_preds})\n",
    "\n",
    "submission.to_csv( \"submission.csv\"\n",
    "                 , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
